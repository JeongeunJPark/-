{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Attention!(335~360)                   \n",
    "---\n",
    "## 포인트\n",
    "1. seq2seq의 문제점         \n",
    "2. 인코더의 개선-1    \n",
    "3. 디코더의 개선-1    \n",
    "4. 디코더의 개선-2    \n",
    "5. 디코더의 개선-3\n",
    "\n",
    "\n",
    "## 8.1 어텐션의 구조     \n",
    "\n",
    "* 어텐션의 목적 : __어텐션을 이용해서 seq2seq가 필요한 정보에만 주목! 할 수 있게 한다.__    \n",
    "\n",
    "### 8.1.1 seq2seq의 문제점    \n",
    "\n",
    "- seq2seq 의 구조\n",
    "\n",
    "![어텐션구조](./PostingPic/어텐션구조.png)\n",
    "\n",
    "- 문제점 : __인코더의 출력이 \"고정길이 벡터\"이다__ \n",
    "- 고정 길이 벡터 : 입력 문장의 길이에 관계없이, 항상 같은 길이의 벡터로 변환한다.\n",
    "\n",
    "![고정길이벡터의문제점](./PostingPic/고정길이벡터문제.png)\n",
    "> - 출력 h의 고정된 길이에 맞추기 위해, 데이터들을 마구 우겨넣게 된다.  \n",
    "\n",
    "### 8.1.2 인코더 개선       \n",
    "\n",
    "- (이제까지는) LSTM이 마지막 계층의 출력 h 하나만 Decoder에 전달한다.           \n",
    "- 이 때, __Encoder 출력의 길이(h)를 입력 문장의 길이에 따라 바꿔주는 것이 이 개선의 포인트!__   \n",
    "\n",
    "![인코더개선포인트](./PostingPic/인코더개선포인트.png)\n",
    "\n",
    "> - 이렇게 하면 입력된 단어와 같은 수의 벡터를 얻게 된다. (예시 2와 같이)\n",
    "\n",
    "\n",
    "- 많은 딥러닝 프레임워크에서는 RNN 계층(or LSTM, GRU)을 초기화 할 때,       \n",
    "__모든 시각(t)의 은닉 상태 벡터 반환__ vs __마지막 은닉상태 반환(ht)__ 중 선택할 수 있다.\n",
    "\n",
    "> - 후자의 세팅에서 전자로 넘어오게 된다.\n",
    "\n",
    "- 주목할 것 : h에 어떤 정보가 담겨 있는가?        \n",
    "- 임베딩, RNN을 거치면서 입력된 단어($Xt$)에 대한 정보가 많이 포함되어 있으므로, $ht$는 각 단어에 해당하는 벡터, $hs$는 각 단어 벡터들의 집합이라고 볼 수 있을 것이다.\n",
    "\n",
    "> - 이 개선을 통해, Encoder는 모든 시각의 입력 길이에 비례한 정보를 담을 수 있게 되었다.  \n",
    "\n",
    "\n",
    "### 8.1.3 디코더 개선(1)        \n",
    "\n",
    "1) 디코더 개선의 포인트\n",
    "\n",
    "![디코더 개선](./PostingPic/디코더픽.png)\n",
    "\n",
    "> - 기존의 디코더는 인코더의 마지막 계층의 $ht$ 하나를 디코더의 첫 은닉층 값으로 썼다.      \n",
    "__그럼 여기서, $hs$를 전부 사용할 수 있도록 개선해보자.__ \n",
    "\n",
    "\n",
    "2) 디코더 개선의 모양 \n",
    "\n",
    "- 사람이 문장을 번역할 때, '나' == I , '고양이' == Cat       \n",
    "- 입력과 출력의 각 단어 중, 어떤 단어가 서로 대응하는 관계인지(관련되어 있는지)를 seq2seq에 알려줄 수 있을까?\n",
    "\n",
    "![대응관계](./PostingPic/대응관계.png)\n",
    "- 그동안 이런 대응관계(Alingnment)는 사람이 수동으로 만들어 주었음...        \n",
    "\n",
    "- 목표\n",
    "- 1. '도착어 단어' 와 대응 관계에 있는 '출발어 단어'의 정보를 골라내는 것   \n",
    "- 2. 1의 정보를 바탕으로 번역을 수행하는 것         \n",
    "\n",
    "\n",
    "3) 디코더 개선이 적용되면 어떤 모습으로 바뀌는가?\n",
    "\n",
    "![어떤계산](./PostingPic/어떤계산.png)\n",
    "\n",
    "- __'어떤 계산' 층이 받는 것__ \n",
    "1. Encoder에서 받는 $hs$(인코더의 마지막 계층)        \n",
    "2. Decoder에서의 시각별 LSTM의 아웃풋(ht)\n",
    "\n",
    "\n",
    "4) 이 디코더 개선의 문제점\n",
    "\n",
    "- 이 때, 위의 '어떤 계산' 층에서 하고싶은 작업 : $hs$ 에서 그 해당 단어에 대응하는 벡터를 골라내려고 한다. ('선택' 작업)        \n",
    "- 저 단어 벡터의 무더기(hs)에서 '이 스텝에 대응될만한 새로운 벡터를 골라낼거야!'\n",
    "- But, 이 선택 작업은 문제가 있다! 미분할 수가 없다!!\n",
    "\n",
    "> - 왜 미분 못하는게 큰일이야?        \n",
    "> - 우리는 '미분'을 통해 학습했는데, 미분을 못하면 기울기를 전달할 수 없잖아!           \n",
    "\n",
    "\n",
    "5) 이 문제점을 어떻게 해결해야 해?           \n",
    "\n",
    "- 간단하지!            \n",
    "- 하나가 아니라 __모든 것을 선택하되, 가중치로 선택하면 된다__          \n",
    "\n",
    "![디코더1문제점해결](./PostingPic/디코더개선1문제점해결.png)       \n",
    "\n",
    "![이렇게된다](./PostingPic/이렇게된다.png)         \n",
    "\n",
    "- 우리에게 익숙한 행렬 곱셈의 형태가 된다.       \n",
    "- 인코더에서 뽑아온, 각 층의 단어벡터에 대한 정보를 가져온 hs와           \n",
    "- 각 단어의 중요도를 나타내는 a(0~1 사이의 스칼)를 곱해서      \n",
    "- '맥락 벡터'를 의미하는 c를 얻게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78918834 -2.5805504  -0.42416331  0.3095987 ]\n",
      " [ 0.07722395 -0.45160877  1.06730337  1.2202234 ]\n",
      " [ 1.15125162 -0.15692105 -0.35880251  1.18669646]\n",
      " [-1.70539437  1.03425513 -1.23699822 -0.30247732]\n",
      " [-0.84057335 -0.32349209  0.46522783  0.02188176]]\n",
      "\n",
      "[0.8  0.1  0.03 0.05 0.02]\n",
      "\n",
      "[[0.8  0.8  0.8  0.8 ]\n",
      " [0.1  0.1  0.1  0.1 ]\n",
      " [0.03 0.03 0.03 0.03]\n",
      " [0.05 0.05 0.05 0.05]\n",
      " [0.02 0.02 0.02 0.02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#인코더에서 인풋이 5번, 각 단어벡터의 고정 길이는 4\n",
    "T, H = 5,4\n",
    "\n",
    "#이 길이에 맞는 단어벡터를 구하기 위해 랜덤으로 세팅해준 것.\n",
    "hs = np.random.randn(T,H)\n",
    "print(hs)\n",
    "print(\"\")\n",
    "\n",
    "#이 벡터의 가중치를 계산한 a\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "print(a)\n",
    "\n",
    "ar = a.reshape(5,1).repeat(4, axis=1)\n",
    "print(\"\")\n",
    "print(ar)\n",
    "\n",
    "t = hs * ar\n",
    "#print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=0)\n",
    "#print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![디코더계산](./PostingPic/디코더계산.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 역전파시에는 repeat의 역전파를 이용한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57152943 -2.06906591 -0.29590974  0.39061596]\n"
     ]
    }
   ],
   "source": [
    "c = np.sum(t, axis=0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.52474134  0.1913142   0.05466674 -0.11053074 -0.01353912]\n"
     ]
    }
   ],
   "source": [
    "c = np.sum(t, axis=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.16514356]\n",
      "  [ 1.68162998]\n",
      "  [ 1.09551742]\n",
      "  [-0.16113951]\n",
      "  [ 1.4510222 ]]\n",
      "\n",
      " [[ 1.44051753]\n",
      "  [-0.71268211]\n",
      "  [ 0.88305114]\n",
      "  [ 0.52992713]\n",
      "  [ 0.95544577]]\n",
      "\n",
      " [[-0.29902916]\n",
      "  [-0.75485829]\n",
      "  [-0.88885996]\n",
      "  [ 1.86573843]\n",
      "  [-1.16897953]]\n",
      "\n",
      " [[ 1.85365961]\n",
      "  [ 1.11167636]\n",
      "  [ 1.09382347]\n",
      "  [-0.80456192]\n",
      "  [ 0.47669065]]\n",
      "\n",
      " [[-0.39017194]\n",
      "  [ 0.22447589]\n",
      "  [-0.89174378]\n",
      "  [-0.01745114]\n",
      "  [ 0.03845749]]\n",
      "\n",
      " [[ 0.12342105]\n",
      "  [-0.77788807]\n",
      "  [ 1.72106554]\n",
      "  [-0.82594137]\n",
      "  [-0.28195049]]\n",
      "\n",
      " [[ 0.84510419]\n",
      "  [-0.41574294]\n",
      "  [ 0.93489515]\n",
      "  [ 0.06850601]\n",
      "  [ 0.00776509]]\n",
      "\n",
      " [[-0.2061637 ]\n",
      "  [-0.6910097 ]\n",
      "  [ 1.58816055]\n",
      "  [ 0.04311715]\n",
      "  [ 1.21570901]]\n",
      "\n",
      " [[ 0.25476815]\n",
      "  [ 0.62881324]\n",
      "  [ 1.05985461]\n",
      "  [-1.03175727]\n",
      "  [ 0.94863546]]\n",
      "\n",
      " [[ 0.70301234]\n",
      "  [-0.12093519]\n",
      "  [-0.80883177]\n",
      "  [ 1.33325039]\n",
      "  [-0.99258222]]]\n",
      "\n",
      "[[[-9.33033622e-02  3.13258431e-01 -1.18315701e-01  1.11129729e-02]\n",
      "  [ 1.70689937e+00 -1.70091086e+00  3.55080424e-02  3.56478703e+00]\n",
      "  [ 1.63580127e-01 -1.18650056e+00 -4.05021587e-01  2.45903766e+00]\n",
      "  [ 9.38038463e-02  2.15033138e-01  2.16354151e-01 -4.76243555e-02]\n",
      "  [ 1.04845701e+00 -1.10394880e+00 -1.20524954e+00  7.26126136e-01]]\n",
      "\n",
      " [[ 1.07549967e+00  8.62377004e-01 -1.10525921e+00  1.08804036e-01]\n",
      "  [-2.37168254e-01 -7.89439698e-01 -4.11140612e-01  1.77434560e-01]\n",
      "  [-4.16909320e-01 -1.05585254e+00 -1.21137198e-01  1.10822324e+00]\n",
      "  [ 1.97093491e-01 -1.14148970e+00 -2.14603920e-01  4.35726658e-01]\n",
      "  [-2.08299745e-01 -2.02944923e-01  5.35865749e-01 -1.56704146e-01]]\n",
      "\n",
      " [[-2.64505326e-01 -2.79378201e-01  4.07920694e-01  2.41111185e-02]\n",
      "  [ 8.39210932e-01 -1.67840682e+00 -6.70918444e-02  8.67891004e-01]\n",
      "  [ 6.73149055e-01 -1.42213344e+00  6.82762286e-01  3.29204760e-01]\n",
      "  [ 2.32083028e+00 -4.78581322e+00  1.98948331e+00  1.80883460e+00]\n",
      "  [ 1.73883618e-01 -9.15908300e-01  8.81849565e-01  1.06178959e+00]]\n",
      "\n",
      " [[-5.45553455e-01 -1.27000933e-01  1.85988843e-01  3.00795870e+00]\n",
      "  [ 1.52028529e+00  1.74869148e+00  1.81094613e+00  4.42799420e-01]\n",
      "  [-1.33746374e+00  1.15514388e-01 -1.30995475e+00 -2.02922735e-01]\n",
      "  [-1.06398729e-01  4.06754214e-01 -4.55824043e-01  8.75474296e-01]\n",
      "  [-8.12681201e-01 -1.21360168e-01 -7.01859365e-01  3.16549746e-02]]\n",
      "\n",
      " [[-2.29906111e-01  2.93061338e-01 -6.37930200e-02 -4.23112897e-02]\n",
      "  [-2.20547266e-01 -2.75101043e-02  1.66951067e-01  2.07622589e-02]\n",
      "  [ 1.75788782e-01 -3.60638579e-01 -9.44665133e-01 -1.07640443e+00]\n",
      "  [ 1.85146687e-02  2.45721255e-02  3.07313319e-02  4.10052058e-02]\n",
      "  [-1.15550187e-02 -1.34168282e-03  7.77689468e-02  5.72179961e-02]]\n",
      "\n",
      " [[ 1.77434186e-01 -9.08266333e-02  7.65123103e-02  1.97281238e-01]\n",
      "  [ 2.57475550e-01  9.91314552e-01  1.17388236e-01  1.31061619e+00]\n",
      "  [ 3.95255588e-01  1.52334894e+00 -7.22072007e-01  4.34243610e-01]\n",
      "  [ 6.40261875e-02  4.21819296e-01 -3.81466037e-01  1.38291558e+00]\n",
      "  [-3.19631910e-01  5.71586489e-01  3.01239005e-01 -2.48658486e-01]]\n",
      "\n",
      " [[-1.09435048e+00 -7.67025443e-02 -1.75304316e-01 -9.17006356e-01]\n",
      "  [-3.67959480e-01  3.19194511e-02  1.89753103e-01  2.24282884e-01]\n",
      "  [-7.67835713e-01 -5.84675396e-01  7.36043755e-01 -1.57491277e-01]\n",
      "  [ 1.71906603e-03 -1.09315877e-01  7.33538111e-02  5.20461931e-02]\n",
      "  [ 1.10339885e-02  9.92066491e-03 -5.44360683e-03  4.86149210e-03]]\n",
      "\n",
      " [[ 4.75173305e-02  8.58706345e-02  1.63660062e-01  3.04890128e-02]\n",
      "  [-2.40627925e+00 -2.91303412e-01  7.58441810e-01 -2.29002901e-01]\n",
      "  [ 1.33481596e-01  2.34339859e+00 -1.10879449e+00  3.85318104e-01]\n",
      "  [ 5.73327524e-02  4.95240815e-02  9.21083372e-02  2.33366017e-03]\n",
      "  [-5.59741615e-01  8.24117673e-01  7.30257393e-01  3.54434861e-01]]\n",
      "\n",
      " [[ 5.00775608e-01 -1.67056928e-01  1.03599974e-01 -1.53825925e-01]\n",
      "  [ 1.02284495e+00 -7.37341747e-01 -4.43518309e-02 -1.01431902e+00]\n",
      "  [ 9.29378318e-01  1.67691640e+00 -1.55449572e+00  2.21368729e+00]\n",
      "  [ 1.56134995e+00  3.41008331e-02 -4.82869377e-03  1.20527138e+00]\n",
      "  [ 1.18351556e+00 -1.17734903e+00  6.29605282e-01 -1.85760480e+00]]\n",
      "\n",
      " [[ 4.62860282e-01 -4.89307384e-01  9.13142014e-01  2.36429334e-02]\n",
      "  [-5.46814774e-02 -5.33173452e-02  3.06455348e-02 -2.56879838e-01]\n",
      "  [ 3.87816348e-01  8.73001267e-01 -1.31454505e+00  8.59364685e-01]\n",
      "  [ 7.97443486e-01  2.65612585e-01  1.98568690e+00  1.94392473e+00]\n",
      "  [-4.95895945e-02  5.30891677e-01  3.55662732e-01 -1.92209890e+00]]]\n",
      "\n",
      "[[ 2.91943699 -3.46306865 -1.47672464  6.71343944]\n",
      " [ 0.41021584 -2.32734986 -1.31627519  1.67348435]\n",
      " [ 3.74256856 -9.08163998  3.89492401  4.09183107]\n",
      " [-1.28181183  2.02259898 -0.47070319  4.15496465]\n",
      " [-0.26770495 -0.0718569  -0.73300681 -0.99973026]\n",
      " [ 0.5745596   3.41724265 -0.60839849  3.07639813]\n",
      " [-2.21739262 -0.7288537   0.81840275 -0.79330706]\n",
      " [-2.72768919  3.01160757  0.63567311  0.54357274]\n",
      " [ 5.19786439 -0.37073047 -0.87047099  0.39320893]\n",
      " [ 1.54384904  1.1268808   1.97059213  0.64795361]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 미니배치처리된 가중합 구하기\n",
    "\n",
    "N, T, H = 10,5,4\n",
    "hs = np.random.randn(N, T, H)\n",
    "a = np.random.randn(N,T)\n",
    "\n",
    "#ar = a.reshape(N, T, 1).repeat(H, aixs=2)\n",
    "ar = a.reshape(N, T, 1)\n",
    "print(ar)\n",
    "print(\"\")\n",
    "\n",
    "#은닉층 * 가중치합\n",
    "t = hs*ar\n",
    "print(t)\n",
    "print(\"\")\n",
    "\n",
    "#맥락벡터 c\n",
    "c = np.sum(t, axis=1)\n",
    "print(c)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repeat의 역전파        \n",
    "\n",
    "- Repeat의 역전파 => Sum       \n",
    "- Sum의 역전파 => Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grad = [], []\n",
    "        self.cache = None\n",
    "        \n",
    "        #인코더에서 뽑아온 각 층의 벡터 hs, 가중치를 가지고 있는 a\n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "        \n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "\n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N,1,H).repeat(T, axis=1)\n",
    "        dar = dt*hs\n",
    "        dhs = dt*ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "        \n",
    "        return dhs, da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.4 디코더 개선 2              \n",
    "\n",
    "> - 그럼, 여기서 가중치 a는 누가 구하나?            \n",
    "\n",
    "- 당연히 학습을 통해 스스로 알아가도록 해야 한다.       \n",
    "- __a를 어떻게 구하는가?__\n",
    "\n",
    "###### 대응관계를 아는 방법                   \n",
    "\n",
    "![대응관계찾기](./PostingPic/대응관계찾기.png)\n",
    "\n",
    "- hs의 각 층과, 디코더의 h가 얼마나 비슷한지 알기 위해 '벡터의 내적'을 수행 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![a의탄생](./PostingPic/a의탄생.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![a의 리소스](./PostingPic/a의리소스.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 4.78289494e-01 -2.86692898e-01 -4.30685761e-01  2.77766604e-01]\n",
      "  [-3.58345111e-01 -8.14037509e-01 -9.62138736e-01 -1.44416404e-01]\n",
      "  [ 4.38731551e-01 -3.96615107e-03  1.18978446e+00 -3.95779694e-01]\n",
      "  [ 4.75648409e-01  1.93300796e-01  1.41916216e+00  2.23445819e-01]\n",
      "  [ 9.69701728e-02 -6.99125788e-01 -3.16929976e+00 -4.75096324e-01]]\n",
      "\n",
      " [[ 3.66608950e-01 -2.87350927e+00  1.51232721e-01 -1.09545604e-01]\n",
      "  [ 7.66796492e-02 -1.17374388e+00 -3.15536573e-01 -8.49404650e-02]\n",
      "  [ 6.17215245e-02  6.25341232e-01 -4.76730787e-01 -3.14164386e-01]\n",
      "  [-3.40029961e-01  1.09640673e+00 -4.65703462e-02 -4.81011095e-02]\n",
      "  [ 4.38890878e-04  1.09130088e+00  1.46829099e-01  9.50059224e-02]]\n",
      "\n",
      " [[ 3.52122245e+00  2.05525407e-01 -1.63386673e-01  2.23180068e+00]\n",
      "  [-1.19105177e+00 -8.96992651e-03 -1.43476987e-01 -8.72164242e-01]\n",
      "  [ 1.10951750e+00 -8.90647907e-02 -4.06169503e-01  9.13484686e-01]\n",
      "  [-9.83730016e-01 -1.32146221e-01  3.92417822e-02 -4.00486584e+00]\n",
      "  [ 1.86840481e+00 -1.66277817e-01  3.74517593e-01 -1.51733802e+00]]\n",
      "\n",
      " [[ 2.93396372e+00  4.17841733e-02 -8.92640936e-01 -5.50261110e-01]\n",
      "  [-8.19347409e-01  1.02268113e-02  2.31760246e-01 -2.25535938e-01]\n",
      "  [ 1.70644527e+00 -1.31754652e-01  1.12232128e-01  1.43420218e-01]\n",
      "  [ 2.82151308e+00  1.99688431e-02 -6.06745795e-01  9.04390278e-02]\n",
      "  [-7.72309185e-01 -3.97379639e-02  8.91965525e-01 -6.00605076e-01]]\n",
      "\n",
      " [[ 2.73548955e+00 -1.37652042e+00  1.74929137e+00  1.20684060e+00]\n",
      "  [ 5.80248502e-01 -1.15549108e-01 -6.44314626e-01 -5.77386293e-01]\n",
      "  [-1.05572808e+00  1.15489734e-01 -3.27154376e-01 -3.20402536e-01]\n",
      "  [ 2.12940477e+00 -9.72582940e-01 -6.11431794e-01 -1.04657031e-01]\n",
      "  [-1.19082624e+00  1.07247126e+00  1.21564093e+00 -1.58854429e+00]]\n",
      "\n",
      " [[-7.28809754e-01  5.41999476e-01  1.84800854e+00 -3.63843899e-02]\n",
      "  [ 7.59299847e-01  1.88229302e+00 -2.55868663e-01  2.29817430e-02]\n",
      "  [ 4.63349841e-01  9.29070888e-01 -9.95753208e-01 -5.78094335e-03]\n",
      "  [ 7.62948876e-01 -8.22260357e-01  1.80924182e+00  4.21733799e-03]\n",
      "  [-1.20084426e+00  2.82867334e-01 -1.25866008e+00 -2.54080602e-02]]\n",
      "\n",
      " [[ 6.16737489e-01  4.45989721e-01 -7.33610158e-01 -6.19063734e-02]\n",
      "  [ 9.89570350e-01 -1.18035482e+00 -1.36738594e+00  2.71292316e-01]\n",
      "  [ 7.87098295e-02  4.56506164e-01 -2.77056300e-02 -5.44193057e-01]\n",
      "  [ 1.05964846e+00  1.53925184e+00  5.29604059e-01 -1.36065094e+00]\n",
      "  [ 1.25134752e+00 -6.00780705e-02 -6.79385278e-01 -6.69621746e+00]]\n",
      "\n",
      " [[-3.39990666e+00 -5.09849904e-01 -1.27939794e-01  3.16487996e-01]\n",
      "  [ 1.73196158e+00  5.70562823e-01 -1.30222858e+00  5.35806366e-01]\n",
      "  [ 8.43989798e-01 -1.32837146e+00 -9.60425673e-01 -1.70486770e-01]\n",
      "  [ 8.71714079e-01 -1.80658012e+00 -1.61114704e+00  5.55945959e-02]\n",
      "  [ 2.00221414e+00  4.37772974e-01  1.08174477e+00 -1.11166006e-01]]\n",
      "\n",
      " [[ 9.63756751e-02 -8.53764921e-01 -3.59401865e-01 -9.22408419e-01]\n",
      "  [-9.36511423e-02 -1.99551271e+00  2.79707895e-01 -5.72543351e-01]\n",
      "  [-4.84086451e-02  4.08543094e-01  2.39108617e-01  1.45156979e+00]\n",
      "  [-2.67340195e-01  3.52253321e+00  2.04149807e-01 -5.93387039e-02]\n",
      "  [-4.59613800e-02 -2.46964997e+00 -4.69102932e-01 -5.51077165e-01]]\n",
      "\n",
      " [[-1.22758648e+00 -8.33941944e-02  5.22956829e-02 -7.88327348e-02]\n",
      "  [ 2.80319771e-01 -1.19503455e+00 -2.85123169e-02  1.21013457e+00]\n",
      "  [-4.35341585e-01 -4.73313009e-01  5.32235865e-02  2.03281189e-01]\n",
      "  [-1.45966079e+00 -3.26286129e-01 -1.25055471e-02 -1.76599136e+00]\n",
      "  [-5.33482376e-01  6.22046288e-01 -5.59771645e-03  2.37123188e-01]]]\n",
      "\n",
      "[[ 0.03867744 -2.27893776  1.22877016  2.31155719 -4.2465517 ]\n",
      " [-2.46521321 -1.49754127 -0.10383242  0.66170532  1.3335748 ]\n",
      " [ 5.79516187 -2.21566293  1.52776789 -5.0815003   0.55930657]\n",
      " [ 1.53284585 -0.80289629  1.83034296  2.32517516 -0.5206867 ]\n",
      " [ 4.3151011  -0.75700153 -1.58779526  0.440733   -0.49125834]\n",
      " [ 1.62481387  2.40870594  0.39088658  1.75414768 -2.20204507]\n",
      " [ 0.26721068 -1.2868781  -0.03668269  1.76785342 -6.18433329]\n",
      " [-3.72120837  1.53610219 -1.61529411 -2.49041848  3.41056588]\n",
      " [-2.03919953 -2.3819993   2.05081285  3.40000412 -3.53579144]\n",
      " [-1.33751773  0.26690747 -0.65214982 -3.56444383  0.32008938]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#코드로 나타내면 이렇습니다.\n",
    "import numpy as np\n",
    "#import Softmax\n",
    "\n",
    "N, T, H = 10, 5 , 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "#hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "hr = h.reshape(N, 1, H)\n",
    "\n",
    "t = hs * hr\n",
    "print(t)\n",
    "print(\"\")\n",
    "\n",
    "s = np.sum(t, axis=2)\n",
    "print(s)\n",
    "print(\"\")\n",
    "\n",
    "#softmax = Softmax()\n",
    "#a = softmax.forward(s)\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = softmax(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grad = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "        \n",
    "        #인코더에서 뽑아온 각 층의 벡터 hs, 가중치를 가지고 있는 a\n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        hr = h.reshape(N,1,H).repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "        \n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "\n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ds = self.softmax.backward(da)\n",
    "        ds = ds.reshape(N,T,1).repeat(H, axis=2)\n",
    "        dhs = dt*hr\n",
    "        dhr = dt*hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "        \n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.5 디코더 개선 3                \n",
    "\n",
    "![합산계층](./PostingPic/합산계층.png)\n",
    "\n",
    "\n",
    "- Attention Weight : 인코더의 출력 hs와 디코더 인풋을 계산하여 가중치 a를 구한다.               \n",
    "- WeightSum : a와 hs의 가중합을 구하고, 맥락벡터 c를 구한다.            \n",
    "\n",
    "__인코더에서 넘어온 hs를 가지고, 맥락 벡터 c를 구한다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![어텐션위치](./PostingPic/어텐션위치.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 어텐션을 갖춘 seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        \n",
    "        #여기를 주목\n",
    "        #가장 마지막의 1개만 반환한다\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionEncoder(Encoder):\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        \n",
    "        #여기를 주목\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디코더에서의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        \n",
    "        ##여기가 다름\n",
    "        self.attention = TimeAttention()\n",
    "        \n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:,-1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        dec_hs = self.lstm.forward(out)\n",
    "        c = self.attention.forward(enc_hs, dec_hs)\n",
    "        out = np.concatenate((c, dec_hs), axis=2)\n",
    "        score = self.affine.forward(out)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        N, T, H2 = dout.shape\n",
    "        H = H2 // 2\n",
    "\n",
    "        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]\n",
    "        denc_hs, ddec_hs1 = self.attention.backward(dc)\n",
    "        ddec_hs = ddec_hs0 + ddec_hs1\n",
    "        dout = self.lstm.backward(ddec_hs)\n",
    "        dh = self.lstm.dh\n",
    "        denc_hs[:, -1] += dh\n",
    "        self.embed.backward(dout)\n",
    "\n",
    "        return denc_hs\n",
    "\n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        h = enc_hs[:, -1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([sample_id]).reshape((1, 1))\n",
    "\n",
    "            out = self.embed.forward(x)\n",
    "            dec_hs = self.lstm.forward(out)\n",
    "            c = self.attention.forward(enc_hs, dec_hs)\n",
    "            \n",
    "            ##concatenate를 사용해서 attention의 출력과 hs의 출력을 연결\n",
    "            out = np.concatenate((c, dec_hs), axis=2)\n",
    "            \n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(sample_id)\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 단방향 RNN, 양방향 RNN\n",
    "\n",
    "![양방향](./PostingPic/양방.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.(정은) 384p 왜 벡터의 내적을 써서 두 단어의 닮음을 알려고 하는가? 다른 방법은 무엇인가?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q.(창원) \n",
    "p344) 구현 효율을 생각하면 repeat()메서드보다 넘파이의 브로드캐스트를 이용하는 이유?\n",
    "\n",
    "![리피트](./PostingPic/리피트.png) \n",
    "\n",
    "https://stackoverflow.com/questions/59667367/numpy-difference-between-np-repeat-and-np-broadcast-to\n",
    "\n",
    "- broadcast :  not copy the data in the new dimension.\n",
    "- repeat : \n",
    "\n",
    "1. Clearly, the element-wise repetition is not identical to the broadcast. However, if you were to use the axis keyword properly, you could in fact get the right result:\n",
    "\n",
    ": 1단계 더 계산을 거쳐서 모양을 잡아줘야 하기 때문입니다.\n",
    "\n",
    "p344) '1.3.4 계산 그래프'에 따르면 이 작업은 계산 그래프로는 Repeat노드에 해당?       \n",
    "- 예쓰으으으으으으\n",
    "- 밑시딥2, 50p\n",
    "\n",
    "![리피트계산](./PostingPic/리피트계산.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 길이가 D인 배열을 N개만큼 복제해서 쌓아놓음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
